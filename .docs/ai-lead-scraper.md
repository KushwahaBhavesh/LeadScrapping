# AI Lead Scraping Platform - Master Implementation Plan

**Version**: 1.0  
**Created**: 2026-02-09  
**Project Type**: WEB (Next.js Full-Stack Application)  
**Target**: MVP for 10K users ‚Üí Scale to 1M users in Phase 3

---

## üìã Overview

### What We're Building

A comprehensive AI-powered lead scraping platform that extracts, qualifies, and manages leads from web pages and websites. The platform combines web scraping capabilities with AI-driven lead qualification and scoring, wrapped in a modern, scalable SaaS architecture.

### Why This Matters

- **Problem**: Manual lead generation is time-consuming and inefficient
- **Solution**: Automated, intelligent lead extraction with AI qualification
- **Value**: Save 80% of time on lead research while improving lead quality

### Success Criteria

- ‚úÖ Successfully scrape and extract leads from 95%+ of web pages
- ‚úÖ AI qualification accuracy >85% compared to manual scoring
- ‚úÖ Handle 10K concurrent users on MVP (Phase 1-2)
- ‚úÖ Platform response time <2s for all queries
- ‚úÖ 99.9% uptime SLA
- ‚úÖ GDPR/SOC 2 compliance ready

---

## üéØ User Requirements Summary

### Confirmed Decisions

1. **MCP Integration**: Both existing + custom MCP servers
2. **Scalability Path**: MVP for ~10K users ‚Üí Scale in Phase 3
3. **AI Qualification**: Advanced (intent/buying signals) + Custom user-defined rules
4. **Credit System**: Hybrid (per URL + data volume extracted)

### Core Features

- Multi-method URL input (single, bulk, sitemap)
- AI-powered data extraction (emails, phones, company info, social profiles)
- Advanced lead qualification with custom scoring
- Real-time dashboard and analytics
- CRM-lite lead management
- Export (CSV, JSON, API)
- Webhook/integration capabilities

---

## üèóÔ∏è Tech Stack Decisions

### Frontend Layer

- **Framework**: Next.js 14+ (App Router, Server Components)
- **Runtime**: React 18+ with TypeScript 5+
- **Styling**: Tailwind CSS v4 + shadcn/ui components
- **State Management**: Zustand (client) + React Query (server state)
- **Form Handling**: React Hook Form + Zod validation
- **Rationale**: Modern, performant, excellent DX, built-in optimizations

### Backend Layer

- **Runtime**: Node.js 20+ LTS
- **API**: Next.js API Routes + Server Actions
- **Database**: PostgreSQL via Supabase
- **Auth**: Supabase Auth (JWT + Row-Level Security)
- **Job Queue**: Inngest (serverless-friendly) or BullMQ
- **Caching**: Upstash Redis (edge-compatible)
- **Rationale**: Unified Next.js stack, serverless-ready, scales to 1M users

### AI/MCP Layer

- **MCP Framework**: Model Context Protocol SDK
- **Custom MCP Servers**:
  - `lead-scraper-mcp`: Puppeteer/Playwright web scraping
  - `lead-qualifier-mcp`: Claude/GPT integration for qualification
  - `data-enrichment-mcp`: External API integrations (Clearbit, Hunter.io)
- **Existing MCP Servers**: To be identified based on ecosystem
- **Rationale**: Modular, maintainable, upgradeable AI capabilities

### Infrastructure

- **Hosting**: Vercel (frontend) + Railway/Fly.io (backend services)
- **Database**: Supabase (managed PostgreSQL)
- **Storage**: Supabase Storage (S3-compatible)
- **Monitoring**: Sentry + PostHog/Mixpanel
- **CDN**: Vercel Edge Network
- **Rationale**: Fast deployment, auto-scaling, global edge network

---

## üìÅ File Structure

```
/var/www/html/Bhavesh/LeadScrapping/
‚îú‚îÄ‚îÄ .docs/                          # Documentation root
‚îÇ   ‚îú‚îÄ‚îÄ PRD.md                      # Product Requirements
‚îÇ   ‚îú‚îÄ‚îÄ SYSTEM_DESIGN.md            # Architecture & Design
‚îÇ   ‚îú‚îÄ‚îÄ APP_FLOW.md                 # User Flows & Navigation
‚îÇ   ‚îú‚îÄ‚îÄ UI_UX_DESIGN.md             # Design Patterns
‚îÇ   ‚îú‚îÄ‚îÄ ROADMAP.md                  # Development Timeline
‚îÇ   ‚îî‚îÄ‚îÄ API_DOCS.md                 # API Documentation
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ app/                        # Next.js App Router
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ (auth)/                 # Auth group
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ login/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ register/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ verify/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ (dashboard)/            # Dashboard group (protected)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ layout.tsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ page.tsx            # Main dashboard
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ scrape/             # Scraping interface
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ leads/              # Leads management
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ analytics/          # Analytics dashboard
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ settings/           # Settings
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/                    # API routes
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ scrape/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ leads/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ webhooks/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ mcp/                # MCP server endpoints
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ layout.tsx              # Root layout
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ page.tsx                # Landing page
‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ui/                     # shadcn/ui components
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dashboard/              # Dashboard components
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ leads/                  # Lead components
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ scraping/               # Scraping components
‚îÇ   ‚îú‚îÄ‚îÄ lib/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ supabase/               # Supabase client
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mcp/                    # MCP client utilities
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ scraper/                # Scraping logic
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ai/                     # AI qualification
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ utils/                  # Utilities
‚îÇ   ‚îú‚îÄ‚îÄ types/                      # TypeScript types
‚îÇ   ‚îî‚îÄ‚îÄ styles/                     # Global styles
‚îú‚îÄ‚îÄ mcp-servers/                    # Custom MCP servers
‚îÇ   ‚îú‚îÄ‚îÄ lead-scraper/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ package.json
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îÇ   ‚îú‚îÄ‚îÄ lead-qualifier/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ package.json
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îÇ   ‚îî‚îÄ‚îÄ data-enrichment/
‚îÇ       ‚îú‚îÄ‚îÄ src/
‚îÇ       ‚îú‚îÄ‚îÄ package.json
‚îÇ       ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ supabase/
‚îÇ   ‚îú‚îÄ‚îÄ migrations/                 # Database migrations
‚îÇ   ‚îú‚îÄ‚îÄ functions/                  # Edge functions
‚îÇ   ‚îî‚îÄ‚îÄ seed.sql                    # Seed data
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ unit/
‚îÇ   ‚îú‚îÄ‚îÄ integration/
‚îÇ   ‚îî‚îÄ‚îÄ e2e/
‚îú‚îÄ‚îÄ .env.example
‚îú‚îÄ‚îÄ .env.local
‚îú‚îÄ‚îÄ next.config.js
‚îú‚îÄ‚îÄ tailwind.config.ts
‚îú‚îÄ‚îÄ tsconfig.json
‚îî‚îÄ‚îÄ package.json
```

---

## üìã Task Breakdown

### Phase 1: Foundation (Week 1-4) - MVP Core

#### TASK 1.1: Project Setup & Configuration

- **Agent**: `backend-specialist`
- **Skills**: `nodejs-best-practices`, `clean-code`
- **Priority**: P0
- **Dependencies**: None
- **INPUT**: Tech stack decisions
- **OUTPUT**:
  - Next.js 14+ project initialized
  - Tailwind CSS v4 + shadcn/ui configured
  - TypeScript strict mode enabled
  - ESLint + Prettier configured
  - `.env.example` with all required variables
- **VERIFY**:
  ```bash
  npm run dev  # Server starts on port 3000
  npm run lint # No errors
  npx tsc --noEmit # No type errors
  ```

#### TASK 1.2: Supabase Setup & Database Schema

- **Agent**: `backend-specialist`
- **Skills**: `database-design`, `clean-code`
- **Priority**: P0
- **Dependencies**: TASK 1.1
- **INPUT**: Database schema design from SYSTEM_DESIGN.md
- **OUTPUT**:
  - Supabase project created
  - PostgreSQL schema with tables:
    - `users`, `organizations`, `teams`
    - `scraping_jobs`, `scraped_leads`, `lead_enrichment`
    - `credits`, `subscriptions`, `api_keys`
    - `webhooks`, `integrations`
  - Row-Level Security (RLS) policies
  - Indexes for performance
  - Migration files in `supabase/migrations/`
- **VERIFY**:
  ```bash
  # Check schema in Supabase Studio
  # Run migrations: supabase db push
  # Verify RLS policies are active
  ```

#### TASK 1.3: Authentication System

- **Agent**: `backend-specialist`
- **Skills**: `nodejs-best-practices`, `clean-code`
- **Priority**: P0
- **Dependencies**: TASK 1.2
- **INPUT**: Supabase Auth configuration
- **OUTPUT**:
  - Supabase Auth integration
  - JWT token handling (HTTP-only cookies)
  - Role-based access control (RBAC)
  - Auth middleware
  - Login/Register pages
  - Email verification flow
- **VERIFY**:
  ```bash
  # Test user registration flow
  # Test login with valid/invalid credentials
  # Test protected routes redirect
  # Verify JWT token in cookies
  ```

#### TASK 1.4: Design System & Component Library

- **Agent**: `frontend-specialist`
- **Skills**: `frontend-design`, `tailwind-patterns`, `clean-code`
- **Priority**: P1
- **Dependencies**: TASK 1.1
- **INPUT**: UI_UX_DESIGN.md specifications
- **OUTPUT**:
  - shadcn/ui components installed
  - Custom design tokens (colors, typography, spacing)
  - Reusable components:
    - Buttons, Forms, Inputs
    - Data tables with pagination
    - Modals, Dialogs, Toasts
    - Loading states, Skeletons
    - Empty states, Error states
  - Responsive breakpoints configured
- **VERIFY**:
  ```bash
  # Visual inspection of component library
  # Test on mobile (< 640px), tablet (640-1024px), desktop (> 1024px)
  # Check color contrast with accessibility_checker.py
  ```

#### TASK 1.5: Dashboard Layout & Navigation

- **Agent**: `frontend-specialist`
- **Skills**: `frontend-design`, `react-best-practices`
- **Priority**: P1
- **Dependencies**: TASK 1.3, TASK 1.4
- **INPUT**: APP_FLOW.md navigation structure
- **OUTPUT**:
  - Dashboard layout with sidebar navigation
  - Top navigation bar with user menu
  - Breadcrumb navigation
  - Mobile-responsive hamburger menu
  - Real-time user state display
- **VERIFY**:
  ```bash
  # Navigate through all menu items
  # Test on mobile and desktop
  # Verify protected routes work
  python .agent/skills/frontend-design/scripts/ux_audit.py .
  ```

### Phase 2: Core Features (Week 5-8) - Lead Scraping Engine

#### TASK 2.1: MCP Server Architecture Setup

- **Agent**: `backend-specialist`
- **Skills**: `mcp-builder`, `architecture`
- **Priority**: P0
- **Dependencies**: TASK 1.2
- **INPUT**: MCP integration strategy
- **OUTPUT**:
  - MCP server boilerplate for 3 custom servers:
    1. `lead-scraper-mcp`
    2. `lead-qualifier-mcp`
    3. `data-enrichment-mcp`
  - MCP client integration in Next.js
  - Environment configuration for MCP connections
  - Error handling and fallback mechanisms
- **VERIFY**:
  ```bash
  # Start all MCP servers
  # Test connection from Next.js app
  # Verify error handling with offline server
  ```

#### TASK 2.2: Lead Scraper MCP Server

- **Agent**: `backend-specialist`
- **Skills**: `nodejs-best-practices`, `mcp-builder`
- **Priority**: P0
- **Dependencies**: TASK 2.1
- **INPUT**: Scraping requirements from PRD.md
- **OUTPUT**:
  - Puppeteer/Playwright integration
  - URL validation and sanitization
  - Data extraction patterns:
    - Email addresses (regex + validation)
    - Phone numbers (international formats)
    - Company information (name, address)
    - Social media profiles (LinkedIn, Twitter)
  - Sitemap parsing
  - Rate limiting and retry logic
  - Anti-bot detection handling
- **VERIFY**:
  ```bash
  # Test scraping on 10 diverse websites
  # Verify email extraction accuracy >90%
  # Test rate limiting prevents blocks
  # Measure avg scrape time per URL
  ```

#### TASK 2.3: Lead Qualifier MCP Server (AI)

- **Agent**: `backend-specialist`
- **Skills**: `nodejs-best-practices`, `mcp-builder`
- **Priority**: P0
- **Dependencies**: TASK 2.2
- **INPUT**: AI qualification criteria (advanced + custom)
- **OUTPUT**:
  - Claude/GPT API integration
  - Qualification prompt engineering
  - Advanced signals detection:
    - Intent signals (hiring, buying keywords)
    - Buying signals (pricing, demo requests)
    - Engagement patterns (activity, recency)
  - Custom scoring rules engine
  - Lead score calculation (0-100)
  - Qualification notes generation
- **VERIFY**:
  ```bash
  # Test with 20 sample leads
  # Compare AI scores with manual scores
  # Verify accuracy >85%
  # Test custom rule creation
  ```

#### TASK 2.4: Data Enrichment MCP Server

- **Agent**: `backend-specialist`
- **Skills**: `nodejs-best-practices`, `api-patterns`
- **Priority**: P1
- **Dependencies**: TASK 2.2
- **INPUT**: Third-party API integrations
- **OUTPUT**:
  - Integration with enrichment APIs:
    - Clearbit (company data)
    - Hunter.io (email verification)
    - LinkedIn API (professional data)
  - Data normalization and merging
  - Confidence scoring for enriched data
  - Caching to reduce API costs
- **VERIFY**:
  ```bash
  # Test enrichment on 10 leads
  # Verify data merge accuracy
  # Check cache hit rate >70%
  ```

#### TASK 2.5: Scraping Job Queue System

- **Agent**: `backend-specialist`
- **Skills**: `nodejs-best-practices`, `server-management`
- **Priority**: P0
- **Dependencies**: TASK 2.2
- **INPUT**: Job queue design (Inngest or BullMQ)
- **OUTPUT**:
  - Job queue implementation (Inngest preferred)
  - Job types: single URL, bulk, sitemap
  - Job priority levels
  - Job status tracking (pending, processing, completed, failed)
  - Progress updates via webhooks
  - Retry logic for failed jobs
  - Job cancellation capability
- **VERIFY**:
  ```bash
  # Create 100 scraping jobs
  # Verify concurrent processing
  # Test job cancellation
  # Check retry on failures
  ```

#### TASK 2.6: Scraping Interface (Frontend)

- **Agent**: `frontend-specialist`
- **Skills**: `frontend-design`, `react-best-practices`
- **Priority**: P1
- **Dependencies**: TASK 1.5, TASK 2.5
- **INPUT**: APP_FLOW.md scraping flow
- **OUTPUT**:
  - URL input interface:
    - Single URL input with validation
    - Bulk URL input (textarea + file upload CSV)
    - Sitemap URL input
  - Advanced options panel:
    - Scraping depth selector
    - Custom CSS selectors
    - Data filters
  - Live preview panel
  - Progress indicator with real-time updates
  - "Start Scraping" CTA with credit check
- **VERIFY**:
  ```bash
  # Test all input methods
  # Verify validation works
  # Test progress updates in real-time
  # Check credit deduction
  python .agent/skills/frontend-design/scripts/ux_audit.py .
  ```

#### TASK 2.7: Leads Table & Management

- **Agent**: `frontend-specialist`
- **Skills**: `frontend-design`, `react-best-practices`
- **Priority**: P1
- **Dependencies**: TASK 2.6
- **INPUT**: UI_UX_DESIGN.md leads table design
- **OUTPUT**:
  - Sortable/filterable data table
  - Columns: Name, Email, Phone, Company, Score, Status, Date
  - Bulk actions (export, delete, tag)
  - Lead detail modal with full information
  - Lead scoring visualization
  - Export options (CSV, JSON)
  - Search and advanced filters
- **VERIFY**:
  ```bash
  # Load table with 1000 leads
  # Test sorting/filtering performance
  # Verify bulk actions work
  # Test export formats
  ```

### Phase 3: Advanced Features (Week 9-12) - Scale & Polish

#### TASK 3.1: Credit System Implementation

- **Agent**: `backend-specialist`
- **Skills**: `database-design`, `nodejs-best-practices`
- **Priority**: P0
- **Dependencies**: TASK 1.2
- **INPUT**: Hybrid credit model design
- **OUTPUT**:
  - Credit calculation logic:
    - Base credits per URL scraped
    - Additional credits per MB of data extracted
  - Credit deduction on job creation
  - Credit balance tracking
  - Credit purchase/subscription integration
  - Low credit warnings
  - Credit transaction history
- **VERIFY**:
  ```bash
  # Test credit deduction on scraping
  # Verify data volume calculation
  # Test low balance warnings
  # Check transaction history accuracy
  ```

#### TASK 3.2: Analytics Dashboard

- **Agent**: `frontend-specialist`
- **Skills**: `frontend-design`, `react-best-practices`
- **Priority**: P1
- **Dependencies**: TASK 2.7
- **INPUT**: UI_UX_DESIGN.md analytics design
- **OUTPUT**:
  - Stats cards (total leads, success rate, credits)
  - Charts:
    - Leads over time (line chart)
    - Lead quality distribution (bar chart)
    - Success/failure rate (pie chart)
    - Top sources (bar chart)
  - Recent activity feed
  - Export analytics data
- **VERIFY**:
  ```bash
  # Verify chart data accuracy
  # Test date range filters
  # Check performance with large datasets
  python .agent/skills/frontend-design/scripts/ux_audit.py .
  ```

#### TASK 3.3: Webhook & Integration System

- **Agent**: `backend-specialist`
- **Skills**: `api-patterns`, `nodejs-best-practices`
- **Priority**: P1
- **Dependencies**: TASK 2.5
- **INPUT**: API_DOCS.md webhook specifications
- **OUTPUT**:
  - Webhook endpoint registration
  - Webhook event types:
    - `scraping.job.completed`
    - `scraping.job.failed`
    - `lead.qualified`
    - `credit.low`
  - Webhook delivery with retries
  - Webhook signature verification
  - Integration templates (Zapier, Make)
- **VERIFY**:
  ```bash
  # Register test webhook
  # Trigger events and verify delivery
  # Test retry logic on failures
  # Verify signature validation
  ```

#### TASK 3.4: API Key Management & Public API

- **Agent**: `backend-specialist`
- **Skills**: `api-patterns`, `nodejs-best-practices`
- **Priority**: P1
- **Dependencies**: TASK 1.3
- **INPUT**: API_DOCS.md API specifications
- **OUTPUT**:
  - API key generation/revocation
  - API key scoping (read/write permissions)
  - Rate limiting per API key
  - Public REST API endpoints:
    - POST `/api/v1/scrape` - Create scraping job
    - GET `/api/v1/jobs/:id` - Get job status
    - GET `/api/v1/leads` - List leads
    - GET `/api/v1/leads/:id` - Get lead details
    - DELETE `/api/v1/leads/:id` - Delete lead
  - API documentation (OpenAPI/Swagger)
- **VERIFY**:
  ```bash
  # Generate API key
  # Test all endpoints with Postman
  # Verify rate limiting
  # Check API docs are accurate
  ```

#### TASK 3.5: Scalability Enhancements (10K ‚Üí 1M)

- **Agent**: `backend-specialist`
- **Skills**: `performance-profiling`, `server-management`, `architecture`
- **Priority**: P0
- **Dependencies**: ALL previous tasks
- **INPUT**: Scalability requirements
- **OUTPUT**:
  - Database connection pooling (PgBouncer)
  - Query optimization and indexing
  - Redis caching implementation:
    - API response caching
    - Session storage
    - Rate limit counters
  - CDN configuration for static assets
  - Database read replicas strategy
  - Horizontal scaling preparation:
    - Stateless server design
    - Session externalization
    - Background job distribution
  - Load testing results (K6 or Artillery)
- **VERIFY**:
  ```bash
  # Run load tests: 10K concurrent users
  # Measure response times <2s
  # Check database query performance
  # Verify cache hit rates >80%
  python .agent/skills/performance-profiling/scripts/bundle_analyzer.py
  ```

#### TASK 3.6: Security Hardening

- **Agent**: `backend-specialist`
- **Skills**: `vulnerability-scanner`, `nodejs-best-practices`
- **Priority**: P0
- **Dependencies**: ALL previous tasks
- **INPUT**: Security requirements from PRD.md
- **OUTPUT**:
  - OWASP Top 10 mitigation
  - Rate limiting (per user, per IP)
  - Input validation and sanitization
  - SQL injection prevention
  - XSS protection
  - CSRF tokens
  - Bot detection and blocking
  - Secrets management (environment variables)
  - Data encryption at rest and in transit
  - Audit logging
- **VERIFY**:
  ```bash
  python .agent/skills/vulnerability-scanner/scripts/security_scan.py .
  python .agent/skills/vulnerability-scanner/scripts/dependency_analyzer.py .
  # Run penetration tests
  # Verify all secrets are secure
  ```

#### TASK 3.7: SEO & Performance Optimization

- **Agent**: `frontend-specialist`
- **Skills**: `seo-fundamentals`, `performance-profiling`
- **Priority**: P2
- **Dependencies**: TASK 1.5
- **INPUT**: SEO requirements
- **OUTPUT**:
  - Meta tags for all pages
  - OpenGraph tags
  - Sitemap.xml
  - Robots.txt
  - Schema.org structured data
  - Image optimization (Next.js Image)
  - Code splitting
  - Bundle size optimization
  - Core Web Vitals optimization
- **VERIFY**:
  ```bash
  python .agent/skills/seo-fundamentals/scripts/seo_checker.py .
  python .agent/skills/performance-profiling/scripts/lighthouse_audit.py http://localhost:3000
  # Target: Lighthouse score >90
  ```

#### TASK 3.8: E2E Testing & QA

- **Agent**: `backend-specialist`
- **Skills**: `webapp-testing`, `testing-patterns`
- **Priority**: P1
- **Dependencies**: ALL previous tasks
- **INPUT**: Test scenarios from APP_FLOW.md
- **OUTPUT**:
  - Playwright E2E tests:
    - User registration flow
    - Login flow
    - Create scraping job flow
    - View leads flow
    - Export leads flow
  - Unit tests for critical functions
  - Integration tests for API endpoints
  - Test coverage >80%
- **VERIFY**:
  ```bash
  npm run test
  python .agent/skills/webapp-testing/scripts/playwright_runner.py http://localhost:3000 --screenshot
  # All tests pass
  # Coverage report shows >80%
  ```

---

## üìä MCP Integration Strategy

### Custom MCP Servers to Build

#### 1. Lead Scraper MCP Server

**Purpose**: Web scraping with Puppeteer/Playwright  
**Tools**:

- `scrape_url(url, options)` - Scrape single URL
- `scrape_sitemap(sitemap_url)` - Parse and scrape sitemap
- `extract_emails(html)` - Extract email addresses
- `extract_phones(html)` - Extract phone numbers
- `extract_social(html)` - Extract social media links

**Resources**:

- `scraping-config` - Configuration for selectors and patterns

**Implementation Priority**: Phase 2, Week 5

#### 2. Lead Qualifier MCP Server

**Purpose**: AI-powered lead qualification  
**Tools**:

- `qualify_lead(lead_data, rules)` - Qualify single lead
- `batch_qualify(leads, rules)` - Qualify multiple leads
- `generate_score(lead_data)` - Calculate lead score
- `detect_signals(content)` - Detect intent/buying signals

**Resources**:

- `qualification-prompts` - AI prompt templates
- `scoring-rules` - Custom scoring rule definitions

**Implementation Priority**: Phase 2, Week 6

#### 3. Data Enrichment MCP Server

**Purpose**: Enrich leads with external data  
**Tools**:

- `enrich_company(domain)` - Get company data
- `verify_email(email)` - Verify email validity
- `lookup_linkedin(name, company)` - Find LinkedIn profile
- `enrich_batch(leads)` - Batch enrichment

**Resources**:

- `enrichment-cache` - Cached enrichment data

**Implementation Priority**: Phase 2, Week 7

### Existing MCP Servers to Integrate

- **Research Phase**: Explore MCP ecosystem for:
  - Web scraping utilities
  - AI/LLM integrations
  - Data validation tools
- **Integration**: Phase 2, Week 5-6

---

## üìà Scalability Roadmap

### MVP (Phase 1-2): 10K Users

- **Architecture**: Monolithic Next.js app
- **Database**: Single PostgreSQL instance on Supabase
- **Caching**: Upstash Redis (basic)
- **Queue**: Inngest (managed)
- **Expected Load**:
  - 100 concurrent scraping jobs
  - 1K API requests/minute
  - 50GB database storage

### Scale Phase (Phase 3): 100K Users

- **Enhancements**:
  - Database read replicas
  - Advanced Redis caching
  - CDN for all static assets
  - Connection pooling (PgBouncer)
- **Expected Load**:
  - 1K concurrent scraping jobs
  - 10K API requests/minute
  - 500GB database storage

### Enterprise (Post-Launch): 1M Users

- **Architecture**: Microservices (if needed)
- **Database**: Sharding or distributed (CockroachDB)
- **Caching**: Redis cluster
- **Queue**: Distributed queue system
- **Infrastructure**: Multi-region deployment
- **Expected Load**:
  - 10K concurrent scraping jobs
  - 100K API requests/minute
  - 5TB+ database storage

---

## üõ°Ô∏è Security & Compliance

### Phase 1 (MVP)

- [x] Supabase Auth with JWT
- [x] Row-Level Security (RLS)
- [x] Input validation (Zod)
- [x] Rate limiting (per IP)
- [x] Secrets in environment variables

### Phase 2 (Beta)

- [ ] Bot detection
- [ ] OWASP Top 10 mitigation
- [ ] Audit logging
- [ ] Data encryption at rest

### Phase 3 (Production)

- [ ] SOC 2 compliance preparation
- [ ] GDPR compliance (data deletion, export)
- [ ] Penetration testing
- [ ] Bug bounty program

---

## üìö Documentation Deliverables

All documentation follows the structure defined in `.docs/documentation guide.md`:

### 1. PRD.md (Product Requirements Document)

**Location**: `.docs/PRD.md`  
**Status**: To be created  
**Sections**:

- Problem Statement
- Goals & Objectives
- Success Metrics
- Target Personas
- Features & Requirements (P0, P1, P2)
- Out of Scope
- User Scenarios
- Non-Functional Requirements

### 2. SYSTEM_DESIGN.md (Architecture & Tech Stack)

**Location**: `.docs/SYSTEM_DESIGN.md`  
**Status**: To be created  
**Sections**:

- System Architecture Diagram
- Technology Stack Deep Dive
- Database Schema Design
- Scalability Strategy
- Security Architecture
- MCP Server Integration Pattern

### 3. APP_FLOW.md (Application Flow & Navigation)

**Location**: `.docs/APP_FLOW.md`  
**Status**: To be created  
**Sections**:

- Entry Points
- Core User Flows (Registration, Scraping, Lead Management)
- Navigation Map
- Screen Inventory
- Decision Points
- Error Handling Flows

### 4. UI_UX_DESIGN.md (Design Patterns & Wireframes)

**Location**: `.docs/UI_UX_DESIGN.md`  
**Status**: To be created  
**Sections**:

- Design System Specification
- Page-by-Page Wireframes
- Component Library
- Responsive Design Strategy
- Interaction Patterns

### 5. ROADMAP.md (Development Timeline)

**Location**: `.docs/ROADMAP.md`  
**Status**: To be created  
**Sections**:

- Phase 1: MVP (Weeks 1-4)
- Phase 2: Beta (Weeks 5-8)
- Phase 3: Scale (Weeks 9-12)
- Milestones & Deliverables

### 6. API_DOCS.md (API Documentation)

**Location**: `.docs/API_DOCS.md`  
**Status**: To be created  
**Sections**:

- Authentication Endpoints
- Scraping Job Endpoints
- Lead Management Endpoints
- Webhook Endpoints
- Integration Endpoints
- OpenAPI/Swagger Specification

---

## ‚úÖ Phase X: Final Verification Checklist

### Pre-Deployment Verification

#### Step 1: Code Quality

```bash
# Lint & Type Check
npm run lint
npx tsc --noEmit
```

**Expected**: No errors

#### Step 2: Security Scan

```bash
python .agent/skills/vulnerability-scanner/scripts/security_scan.py .
python .agent/skills/vulnerability-scanner/scripts/dependency_analyzer.py .
```

**Expected**: No critical vulnerabilities

#### Step 3: Build Verification

```bash
npm run build
```

**Expected**: Build succeeds, bundle size <500kB

#### Step 4: UX Audit

```bash
python .agent/skills/frontend-design/scripts/ux_audit.py .
python .agent/skills/frontend-design/scripts/accessibility_checker.py .
```

**Expected**: No critical UX violations, WCAG AA compliance

#### Step 5: Performance Audit

```bash
# Start dev server first: npm run dev
python .agent/skills/performance-profiling/scripts/lighthouse_audit.py http://localhost:3000
```

**Expected**:

- Performance >90
- Accessibility >90
- Best Practices >90
- SEO >90

#### Step 6: E2E Tests

```bash
python .agent/skills/webapp-testing/scripts/playwright_runner.py http://localhost:3000 --screenshot
```

**Expected**: All tests pass

#### Step 7: Load Testing

```bash
# Install K6: https://k6.io/docs/getting-started/installation/
k6 run tests/load/scraping-load-test.js
```

**Expected**:

- p95 response time <2s
- Error rate <1%
- 10K concurrent users supported

### Manual Verification

#### User Flows

- [ ] Registration ‚Üí Email Verification ‚Üí Dashboard
- [ ] Create Single URL Scraping Job ‚Üí View Results
- [ ] Create Bulk Scraping Job ‚Üí Download CSV Export
- [ ] View Lead Details ‚Üí AI Qualification Notes
- [ ] Purchase Credits ‚Üí Credit Balance Updates
- [ ] Generate API Key ‚Üí Test API Endpoint
- [ ] Configure Webhook ‚Üí Receive Event

#### UI/UX Compliance

- [ ] No purple/violet colors used (Purple Ban)
- [ ] No standard template layouts (Template Ban)
- [ ] Mobile responsive (test on actual devices)
- [ ] Touch targets ‚â•44px on mobile
- [ ] Color contrast meets WCAG AA

#### Documentation Complete

- [ ] PRD.md created and complete
- [ ] SYSTEM_DESIGN.md created and complete
- [ ] APP_FLOW.md created and complete
- [ ] UI_UX_DESIGN.md created and complete
- [ ] ROADMAP.md created and complete
- [ ] API_DOCS.md created and complete
- [ ] README.md with setup instructions
- [ ] Environment variables documented

### Phase X Completion Marker

```markdown
## ‚úÖ PHASE X COMPLETE

- Lint: ‚úÖ Pass
- Security: ‚úÖ No critical issues
- Build: ‚úÖ Success (bundle <500kB)
- UX Audit: ‚úÖ Pass (WCAG AA)
- Lighthouse: ‚úÖ Score >90
- E2E Tests: ‚úÖ All pass
- Load Test: ‚úÖ 10K users, <2s response
- Documentation: ‚úÖ All 6 docs complete
- Date: [To be filled on completion]
```

---

## üéØ Next Steps

1. **User Approval**: Review this plan and provide feedback
2. **Documentation Generation**: Create all 6 documentation files
3. **Phase 1 Kickoff**: Start with TASK 1.1 (Project Setup)
4. **Weekly Checkpoints**: Review progress against task breakdown
5. **Phase X Execution**: Run all verification scripts before deployment

---

## üìù Notes

- **Agent Assignment Priority**:
  - `backend-specialist` for all backend/infrastructure tasks
  - `frontend-specialist` for all UI/UX tasks
  - NO `mobile-developer` (this is a web app)
- **Parallel Execution**:
  - Tasks with different agents can run in parallel
  - Example: TASK 1.4 (frontend) can run while TASK 1.2 (backend) runs
- **Dependencies**:
  - Always complete foundation tasks (P0) before feature tasks (P1)
  - Database schema must be complete before API development
- **MCP Development**:
  - Custom MCP servers are Node.js projects in `/mcp-servers/`
  - Each has its own `package.json` and can be deployed independently
  - Test MCP servers locally before integrating with main app

---

**Plan Version**: 1.0  
**Last Updated**: 2026-02-09  
**Status**: Ready for User Review
